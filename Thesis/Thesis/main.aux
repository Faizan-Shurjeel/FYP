\relax 
\providecommand \babel@aux [2]{\global \let \babel@toc \@gobbletwo }
\@nameuse{bbl@beforestart}
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\babel@aux{english}{}
\@writefile{toc}{\contentsline {chapter}{Declaration}{i}{chapter*.1}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{Final Approval}{ii}{chapter*.2}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{Dedication}{iv}{chapter*.3}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{Acknowledgements}{v}{chapter*.4}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{Abstract}{vi}{chapter*.5}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{List of Abbreviations}{viii}{chapter*.6}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:introduction}{{1}{1}{Introduction}{chapter.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Background of the Study}{1}{section.1.1}\protected@file@percent }
\newlabel{sec:background}{{1.1}{1}{Background of the Study}{section.1.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Problem Statement}{1}{section.1.2}\protected@file@percent }
\newlabel{sec:problem}{{1.2}{1}{Problem Statement}{section.1.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Conceptual Overview of the Hybrid Two-Layer Authentication System}}{2}{figure.caption.7}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:concept_overview}{{1.1}{2}{Conceptual Overview of the Hybrid Two-Layer Authentication System}{figure.caption.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Project Objectives}{2}{section.1.3}\protected@file@percent }
\newlabel{sec:objectives}{{1.3}{2}{Project Objectives}{section.1.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Scope of the Project}{3}{section.1.4}\protected@file@percent }
\newlabel{sec:scope}{{1.4}{3}{Scope of the Project}{section.1.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.5}Significance of the Study}{4}{section.1.5}\protected@file@percent }
\newlabel{sec:significance}{{1.5}{4}{Significance of the Study}{section.1.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.6}Broader Impact (UN SDGs)}{4}{section.1.6}\protected@file@percent }
\newlabel{sec:sdgs}{{1.6}{4}{Broader Impact (UN SDGs)}{section.1.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces Project Alignment with United Nations Sustainable Development Goals}}{5}{figure.caption.8}\protected@file@percent }
\newlabel{fig:sdg_alignment}{{1.2}{5}{Project Alignment with United Nations Sustainable Development Goals}{figure.caption.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.7}Report Organization}{5}{section.1.7}\protected@file@percent }
\newlabel{sec:organization}{{1.7}{5}{Report Organization}{section.1.7}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Literature Review}{6}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:literature}{{2}{6}{Literature Review}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Theoretical Framework and Taxonomy}{6}{section.2.1}\protected@file@percent }
\newlabel{sec:taxonomy}{{2.1}{6}{Theoretical Framework and Taxonomy}{section.2.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Taxonomy of Biometric Recognition Technologies}}{7}{figure.caption.9}\protected@file@percent }
\newlabel{fig:taxonomy}{{2.1}{7}{Taxonomy of Biometric Recognition Technologies}{figure.caption.9}{}}
\citation{mtcnn}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Facial Recognition Pipeline: A Deep Dive}{8}{section.2.2}\protected@file@percent }
\newlabel{sec:face_pipeline}{{2.2}{8}{Facial Recognition Pipeline: A Deep Dive}{section.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Complete Facial Recognition Pipeline from Input to Decision}}{8}{figure.caption.10}\protected@file@percent }
\newlabel{fig:face_pipeline}{{2.2}{8}{Complete Facial Recognition Pipeline from Input to Decision}{figure.caption.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Stage 1: Face Detection - Finding the Face in the Frame}{8}{subsection.2.2.1}\protected@file@percent }
\newlabel{subsec:face_detection}{{2.2.1}{8}{Stage 1: Face Detection - Finding the Face in the Frame}{subsection.2.2.1}{}}
\citation{blazeface}
\citation{facenet}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Visual Comparison of Face Detection Methods on Raspberry Pi 4}}{10}{figure.caption.11}\protected@file@percent }
\newlabel{fig:face_detection_comparison}{{2.3}{10}{Visual Comparison of Face Detection Methods on Raspberry Pi 4}{figure.caption.11}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Stage 2: Face Recognition - Identifying the Face}{10}{subsection.2.2.2}\protected@file@percent }
\newlabel{subsec:face_recognition}{{2.2.2}{10}{Stage 2: Face Recognition - Identifying the Face}{subsection.2.2.2}{}}
\citation{insightface}
\citation{mobilefacenet}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces MobileFaceNet Architecture with Depthwise Separable Convolutions}}{11}{figure.caption.12}\protected@file@percent }
\newlabel{fig:mobilefacenet_arch}{{2.4}{11}{MobileFaceNet Architecture with Depthwise Separable Convolutions}{figure.caption.12}{}}
\citation{facenet}
\citation{arcface}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Visualization of ArcFace Angular Margin Loss vs. Standard Softmax}}{13}{figure.caption.13}\protected@file@percent }
\newlabel{fig:arcface_viz}{{2.5}{13}{Visualization of ArcFace Angular Margin Loss vs. Standard Softmax}{figure.caption.13}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Comprehensive Survey of Speaker Recognition Models}{13}{section.2.3}\protected@file@percent }
\newlabel{sec:voice_models}{{2.3}{13}{Comprehensive Survey of Speaker Recognition Models}{section.2.3}{}}
\citation{ecapa_tdnn}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces Taxonomy of Speaker Recognition Models by Complexity and Efficiency}}{14}{figure.caption.14}\protected@file@percent }
\newlabel{fig:speaker_taxonomy}{{2.6}{14}{Taxonomy of Speaker Recognition Models by Complexity and Efficiency}{figure.caption.14}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Category A: State-of-the-Art \& High-Complexity Models}{14}{subsection.2.3.1}\protected@file@percent }
\newlabel{subsec:voice_sota}{{2.3.1}{14}{Category A: State-of-the-Art \& High-Complexity Models}{subsection.2.3.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces SOTA High-Complexity Speaker Recognition Models}}{15}{table.caption.15}\protected@file@percent }
\newlabel{tab:voice_sota}{{2.1}{15}{SOTA High-Complexity Speaker Recognition Models}{table.caption.15}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Category B \& C: Efficient CNN-based Models}{15}{subsection.2.3.2}\protected@file@percent }
\newlabel{subsec:voice_cnn}{{2.3.2}{15}{Category B \& C: Efficient CNN-based Models}{subsection.2.3.2}{}}
\citation{ge2e}
\citation{resemblyzer}
\@writefile{lot}{\contentsline {table}{\numberline {2.2}{\ignorespaces Efficient CNN-Based Speaker Recognition Models}}{16}{table.caption.16}\protected@file@percent }
\newlabel{tab:voice_cnn}{{2.2}{16}{Efficient CNN-Based Speaker Recognition Models}{table.caption.16}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.3}Category D: RNN-based Models (Our Selected Approach)}{16}{subsection.2.3.3}\protected@file@percent }
\newlabel{subsec:voice_rnn}{{2.3.3}{16}{Category D: RNN-based Models (Our Selected Approach)}{subsection.2.3.3}{}}
\citation{onnx}
\@writefile{lot}{\contentsline {table}{\numberline {2.3}{\ignorespaces RNN-Based Speaker Recognition Models}}{17}{table.caption.17}\protected@file@percent }
\newlabel{tab:voice_rnn}{{2.3}{17}{RNN-Based Speaker Recognition Models}{table.caption.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces Generalized End-to-End (GE2E) Loss Training Mechanism}}{17}{figure.caption.18}\protected@file@percent }
\newlabel{fig:ge2e_loss}{{2.7}{17}{Generalized End-to-End (GE2E) Loss Training Mechanism}{figure.caption.18}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Optimization and the Role of ONNX}{17}{section.2.4}\protected@file@percent }
\newlabel{sec:onnx}{{2.4}{17}{Optimization and the Role of ONNX}{section.2.4}{}}
\citation{onnx_runtime}
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces ONNX Model Conversion and Optimization Pipeline}}{18}{figure.caption.19}\protected@file@percent }
\newlabel{fig:onnx_pipeline}{{2.8}{18}{ONNX Model Conversion and Optimization Pipeline}{figure.caption.19}{}}
\citation{multimodal_camera_ppg}
\citation{multimodal_robustness}
\citation{multimodal_accessibility}
\citation{anti_spoofing_multimodal}
\citation{adaptive_multimodal}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Multimodal Biometric Authentication: State of the Art}{19}{section.2.5}\protected@file@percent }
\newlabel{sec:multimodal_biometrics}{{2.5}{19}{Multimodal Biometric Authentication: State of the Art}{section.2.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.1}Advantages of Multimodal Biometrics}{19}{subsection.2.5.1}\protected@file@percent }
\newlabel{subsec:multimodal_advantages}{{2.5.1}{19}{Advantages of Multimodal Biometrics}{subsection.2.5.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.9}{\ignorespaces Key Advantages of Multimodal Biometric Systems}}{20}{figure.caption.20}\protected@file@percent }
\newlabel{fig:multimodal_advantages}{{2.9}{20}{Key Advantages of Multimodal Biometric Systems}{figure.caption.20}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.2}Fusion Strategies in Multimodal Biometrics}{20}{subsection.2.5.2}\protected@file@percent }
\newlabel{subsec:fusion_strategies}{{2.5.2}{20}{Fusion Strategies in Multimodal Biometrics}{subsection.2.5.2}{}}
\citation{deep_hashing_multimodal}
\citation{ml_score_fusion}
\citation{quality_dependent_fusion}
\citation{audio_visual_lip}
\@writefile{lof}{\contentsline {figure}{\numberline {2.10}{\ignorespaces Comparison of Multimodal Fusion Strategies at Different Levels}}{22}{figure.caption.21}\protected@file@percent }
\newlabel{fig:fusion_strategies}{{2.10}{22}{Comparison of Multimodal Fusion Strategies at Different Levels}{figure.caption.21}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.3}Recent Advances in Audio-Visual Biometrics}{22}{subsection.2.5.3}\protected@file@percent }
\newlabel{subsec:audio_visual_advances}{{2.5.3}{22}{Recent Advances in Audio-Visual Biometrics}{subsection.2.5.3}{}}
\citation{gumbel_bimodal}
\citation{cross_modal_biometric}
\citation{transformer_multimodal}
\citation{transformer_multimodal}
\citation{behavepassdb}
\citation{speakingfaces}
\citation{smartphone_multimodal}
\citation{mobibits}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.4}Multimodal Biometric Databases}{24}{subsection.2.5.4}\protected@file@percent }
\newlabel{subsec:multimodal_databases}{{2.5.4}{24}{Multimodal Biometric Databases}{subsection.2.5.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.11}{\ignorespaces Overview of Major Multimodal Biometric Databases}}{25}{figure.caption.22}\protected@file@percent }
\newlabel{fig:multimodal_databases}{{2.11}{25}{Overview of Major Multimodal Biometric Databases}{figure.caption.22}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.6}Edge Computing and Biometric Systems}{25}{section.2.6}\protected@file@percent }
\newlabel{sec:edge_computing}{{2.6}{25}{Edge Computing and Biometric Systems}{section.2.6}{}}
\citation{privacy_edge_biometric}
\citation{edge_latency_biometric}
\citation{revamp2t}
\citation{network_independent_biometric}
\citation{bandwidth_edge}
\@writefile{lof}{\contentsline {figure}{\numberline {2.12}{\ignorespaces Edge vs. Cloud Biometric Processing: Trade-offs and Considerations}}{26}{figure.caption.23}\protected@file@percent }
\newlabel{fig:edge_vs_cloud}{{2.12}{26}{Edge vs. Cloud Biometric Processing: Trade-offs and Considerations}{figure.caption.23}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.1}The Case for Edge-Based Biometric Processing}{26}{subsection.2.6.1}\protected@file@percent }
\newlabel{subsec:edge_case}{{2.6.1}{26}{The Case for Edge-Based Biometric Processing}{subsection.2.6.1}{}}
\citation{edge_scalability}
\citation{facial_expression_edge}
\citation{smartphone_sensors_auth}
\citation{neuromorphic_vs_edge}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.2}Hardware Platforms for Edge Biometrics}{27}{subsection.2.6.2}\protected@file@percent }
\newlabel{subsec:edge_hardware}{{2.6.2}{27}{Hardware Platforms for Edge Biometrics}{subsection.2.6.2}{}}
\citation{binarynet_covid_mask}
\@writefile{lof}{\contentsline {figure}{\numberline {2.13}{\ignorespaces Edge Hardware Platforms: Performance vs. Power Consumption Trade-offs}}{28}{figure.caption.24}\protected@file@percent }
\newlabel{fig:edge_hardware}{{2.13}{28}{Edge Hardware Platforms: Performance vs. Power Consumption Trade-offs}{figure.caption.24}{}}
\citation{memory_efficient_sv}
\citation{pruning_biometric}
\citation{distillation_edge}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.3}Optimization Techniques for Edge Deployment}{29}{subsection.2.6.3}\protected@file@percent }
\newlabel{subsec:edge_optimization}{{2.6.3}{29}{Optimization Techniques for Edge Deployment}{subsection.2.6.3}{}}
\citation{mobilenet_edge}
\citation{efficientnet_biometric}
\citation{shufflenet_edge}
\citation{squeezenet_biometric}
\citation{edgecnn}
\@writefile{lof}{\contentsline {figure}{\numberline {2.14}{\ignorespaces Model Compression Techniques for Edge Deployment}}{30}{figure.caption.25}\protected@file@percent }
\newlabel{fig:optimization_techniques}{{2.14}{30}{Model Compression Techniques for Edge Deployment}{figure.caption.25}{}}
\citation{edge_emotion_service}
\citation{early_exit_biometric}
\citation{adaptive_resolution}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.4}Real-Time Constraints and System Design}{31}{subsection.2.6.4}\protected@file@percent }
\newlabel{subsec:realtime_constraints}{{2.6.4}{31}{Real-Time Constraints and System Design}{subsection.2.6.4}{}}
\citation{quality_aware_processing}
\@writefile{lof}{\contentsline {figure}{\numberline {2.15}{\ignorespaces Adaptive Processing Pipeline for Resource-Constrained Environments}}{32}{figure.caption.26}\protected@file@percent }
\newlabel{fig:adaptive_processing}{{2.15}{32}{Adaptive Processing Pipeline for Resource-Constrained Environments}{figure.caption.26}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.7}Privacy and Security in Biometric Systems}{32}{section.2.7}\protected@file@percent }
\newlabel{sec:privacy_security}{{2.7}{32}{Privacy and Security in Biometric Systems}{section.2.7}{}}
\citation{encrypted_similarity}
\citation{semba_multimodal}
\@writefile{lof}{\contentsline {figure}{\numberline {2.16}{\ignorespaces Privacy and Security Landscape in Biometric Systems}}{33}{figure.caption.27}\protected@file@percent }
\newlabel{fig:privacy_landscape}{{2.16}{33}{Privacy and Security Landscape in Biometric Systems}{figure.caption.27}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7.1}Privacy-Preserving Biometric Authentication}{33}{subsection.2.7.1}\protected@file@percent }
\newlabel{subsec:privacy_preserving}{{2.7.1}{33}{Privacy-Preserving Biometric Authentication}{subsection.2.7.1}{}}
\citation{federated_biometric}
\citation{differential_privacy_biometric}
\citation{metamorphosis_privacy}
\citation{asvspoof_challenge}
\citation{sasv_optimization}
\@writefile{lof}{\contentsline {figure}{\numberline {2.17}{\ignorespaces Comparison of Privacy-Preserving Techniques for Biometric Authentication}}{35}{figure.caption.28}\protected@file@percent }
\newlabel{fig:privacy_techniques}{{2.17}{35}{Comparison of Privacy-Preserving Techniques for Biometric Authentication}{figure.caption.28}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7.2}Presentation Attack Detection}{35}{subsection.2.7.2}\protected@file@percent }
\newlabel{subsec:pad}{{2.7.2}{35}{Presentation Attack Detection}{subsection.2.7.2}{}}
\citation{ssl_antispoofing}
\citation{deepfake_detection_bimodal}
\citation{multimodal_pad}
\citation{adversarial_voice_attack}
\citation{malacopula_attack}
\citation{adversarial_training_biometric}
\@writefile{lof}{\contentsline {figure}{\numberline {2.18}{\ignorespaces Overview of Presentation Attacks and Countermeasures for Biometric Systems}}{37}{figure.caption.29}\protected@file@percent }
\newlabel{fig:presentation_attacks}{{2.18}{37}{Overview of Presentation Attacks and Countermeasures for Biometric Systems}{figure.caption.29}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7.3}Adversarial Attacks and Defenses}{37}{subsection.2.7.3}\protected@file@percent }
\newlabel{subsec:adversarial}{{2.7.3}{37}{Adversarial Attacks and Defenses}{subsection.2.7.3}{}}
\citation{input_transform_defense}
\citation{certified_defense}
\citation{behavioral_biometric_survey}
\citation{mobile_behavioral_biometric}
\@writefile{toc}{\contentsline {section}{\numberline {2.8}Continuous Authentication and Behavioral Biometrics}{38}{section.2.8}\protected@file@percent }
\newlabel{sec:continuous_auth}{{2.8}{38}{Continuous Authentication and Behavioral Biometrics}{section.2.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.8.1}Behavioral Biometric Modalities}{38}{subsection.2.8.1}\protected@file@percent }
\newlabel{subsec:behavioral_modalities}{{2.8.1}{38}{Behavioral Biometric Modalities}{subsection.2.8.1}{}}
\citation{location_auth}
\citation{temporal_auth}
\citation{environmental_context}
\citation{multidevice_auth}
\citation{zero_trust_metaverse}
\@writefile{lof}{\contentsline {figure}{\numberline {2.19}{\ignorespaces Continuous Authentication Lifecycle with Behavioral Biometrics}}{39}{figure.caption.30}\protected@file@percent }
\newlabel{fig:behavioral_timeline}{{2.19}{39}{Continuous Authentication Lifecycle with Behavioral Biometrics}{figure.caption.30}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.8.2}Context-Aware Authentication}{39}{subsection.2.8.2}\protected@file@percent }
\newlabel{subsec:context_aware}{{2.8.2}{39}{Context-Aware Authentication}{subsection.2.8.2}{}}
\citation{children_sv}
\citation{age_agnostic_sv}
\citation{cross_age_disentangle}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.8.3}Zero-Trust Security Models}{40}{subsection.2.8.3}\protected@file@percent }
\newlabel{subsec:zero_trust}{{2.8.3}{40}{Zero-Trust Security Models}{subsection.2.8.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.9}Domain-Specific Challenges and Solutions}{40}{section.2.9}\protected@file@percent }
\newlabel{sec:domain_specific}{{2.9}{40}{Domain-Specific Challenges and Solutions}{section.2.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.9.1}Cross-Age Speaker Verification}{40}{subsection.2.9.1}\protected@file@percent }
\newlabel{subsec:cross_age}{{2.9.1}{40}{Cross-Age Speaker Verification}{subsection.2.9.1}{}}
\citation{self_distillation_sv}
\citation{self_supervised_sv_wavlm}
\citation{speaker_interpolation}
\citation{text_dependent_sv}
\citation{text_adaptation_sv}
\citation{chinese_numerical_sv}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.9.2}Low-Resource and Few-Shot Learning}{41}{subsection.2.9.2}\protected@file@percent }
\newlabel{subsec:low_resource}{{2.9.2}{41}{Low-Resource and Few-Shot Learning}{subsection.2.9.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.9.3}Text-Dependent vs. Text-Independent Verification}{41}{subsection.2.9.3}\protected@file@percent }
\newlabel{subsec:text_dependent}{{2.9.3}{41}{Text-Dependent vs. Text-Independent Verification}{subsection.2.9.3}{}}
\citation{far_field_sv}
\citation{low_light_enhancement}
\citation{noise_robust_sv}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.9.4}Robustness to Environmental Conditions}{42}{subsection.2.9.4}\protected@file@percent }
\newlabel{subsec:environmental_robustness}{{2.9.4}{42}{Robustness to Environmental Conditions}{subsection.2.9.4}{}}
\citation{explainable_phonetic_sv}
\citation{3d_speaker_toolkit}
\@writefile{toc}{\contentsline {section}{\numberline {2.10}Emerging Trends and Future Directions}{43}{section.2.10}\protected@file@percent }
\newlabel{sec:emerging_trends}{{2.10}{43}{Emerging Trends and Future Directions}{section.2.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.20}{\ignorespaces Emerging Technology Landscape for Biometric Authentication}}{43}{figure.caption.31}\protected@file@percent }
\newlabel{fig:emerging_trends}{{2.20}{43}{Emerging Technology Landscape for Biometric Authentication}{figure.caption.31}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.10.1}Foundation Models for Biometrics}{43}{subsection.2.10.1}\protected@file@percent }
\newlabel{subsec:foundation_models}{{2.10.1}{43}{Foundation Models for Biometrics}{subsection.2.10.1}{}}
\citation{ssl_foundation_biometric}
\citation{attribution_biometric}
\citation{speaker_embedding_interpretation}
\citation{calibration_biometric}
\citation{tinysv}
\citation{binary_nn_biometric}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.10.2}Explainable Biometric Systems}{44}{subsection.2.10.2}\protected@file@percent }
\newlabel{subsec:explainable}{{2.10.2}{44}{Explainable Biometric Systems}{subsection.2.10.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.10.3}Tiny Machine Learning (TinyML)}{44}{subsection.2.10.3}\protected@file@percent }
\newlabel{subsec:tinyml}{{2.10.3}{44}{Tiny Machine Learning (TinyML)}{subsection.2.10.3}{}}
\citation{event_camera_expression}
\citation{synthetic_emotion_faces}
\citation{tts_augmentation}
\citation{synthetic_domain_adapt}
\citation{snn_biometric}
\citation{in_memory_biometric}
\citation{analog_nn_biometric}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.10.4}Synthetic Data and Data Augmentation}{45}{subsection.2.10.4}\protected@file@percent }
\newlabel{subsec:synthetic_data}{{2.10.4}{45}{Synthetic Data and Data Augmentation}{subsection.2.10.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.10.5}Neuromorphic and Alternative Computing Paradigms}{45}{subsection.2.10.5}\protected@file@percent }
\newlabel{subsec:neuromorphic}{{2.10.5}{45}{Neuromorphic and Alternative Computing Paradigms}{subsection.2.10.5}{}}
\citation{depth_width_tradeoff}
\citation{conv_vs_transformer_edge}
\citation{task_specific_models}
\@writefile{toc}{\contentsline {section}{\numberline {2.11}Comparative Analysis and Lessons Learned}{46}{section.2.11}\protected@file@percent }
\newlabel{sec:comparative_analysis}{{2.11}{46}{Comparative Analysis and Lessons Learned}{section.2.11}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.11.1}Model Selection Criteria}{46}{subsection.2.11.1}\protected@file@percent }
\newlabel{subsec:model_selection_criteria}{{2.11.1}{46}{Model Selection Criteria}{subsection.2.11.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.11.2}Architecture Trade-offs}{46}{subsection.2.11.2}\protected@file@percent }
\newlabel{subsec:architecture_tradeoffs}{{2.11.2}{46}{Architecture Trade-offs}{subsection.2.11.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.11.3}Fusion Strategy Selection}{47}{subsection.2.11.3}\protected@file@percent }
\newlabel{subsec:fusion_selection}{{2.11.3}{47}{Fusion Strategy Selection}{subsection.2.11.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.12}Research Gaps and Our Contribution}{47}{section.2.12}\protected@file@percent }
\newlabel{sec:research_gaps}{{2.12}{47}{Research Gaps and Our Contribution}{section.2.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.21}{\ignorespaces Visualization of Research Gaps Addressed by This Work}}{48}{figure.caption.32}\protected@file@percent }
\newlabel{fig:research_gaps}{{2.21}{48}{Visualization of Research Gaps Addressed by This Work}{figure.caption.32}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.13}Chapter Summary}{48}{section.2.13}\protected@file@percent }
\newlabel{sec:lit_review_summary}{{2.13}{48}{Chapter Summary}{section.2.13}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}System Design \& Analysis}{50}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:design}{{3}{50}{System Design \& Analysis}{chapter.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Proposed Methodology: The Hybrid Approach}{50}{section.3.1}\protected@file@percent }
\newlabel{sec:methodology}{{3.1}{50}{Proposed Methodology: The Hybrid Approach}{section.3.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Comparison of Sequential vs. Parallel Authentication Approaches}}{51}{figure.caption.33}\protected@file@percent }
\newlabel{fig:seq_vs_parallel}{{3.1}{51}{Comparison of Sequential vs. Parallel Authentication Approaches}{figure.caption.33}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}System Requirements}{51}{section.3.2}\protected@file@percent }
\newlabel{sec:requirements}{{3.2}{51}{System Requirements}{section.3.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Functional Requirements (FR)}{51}{subsection.3.2.1}\protected@file@percent }
\newlabel{subsec:functional}{{3.2.1}{51}{Functional Requirements (FR)}{subsection.3.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Non-Functional Requirements (NFR)}{52}{subsection.3.2.2}\protected@file@percent }
\newlabel{subsec:nonfunctional}{{3.2.2}{52}{Non-Functional Requirements (NFR)}{subsection.3.2.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Hardware Platform Selection and Justification}{52}{section.3.3}\protected@file@percent }
\newlabel{sec:hardware}{{3.3}{52}{Hardware Platform Selection and Justification}{section.3.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces Hardware Platform Comparison}}{53}{table.caption.34}\protected@file@percent }
\newlabel{tab:hardware_comparison}{{3.1}{53}{Hardware Platform Comparison}{table.caption.34}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Hardware Setup: Raspberry Pi 4 with Camera, Microphone, and GPIO Peripherals}}{53}{figure.caption.35}\protected@file@percent }
\newlabel{fig:pi_setup}{{3.2}{53}{Hardware Setup: Raspberry Pi 4 with Camera, Microphone, and GPIO Peripherals}{figure.caption.35}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}System Architecture/Design Diagrams}{54}{section.3.4}\protected@file@percent }
\newlabel{sec:architecture}{{3.4}{54}{System Architecture/Design Diagrams}{section.3.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.1}High-Level Architecture}{54}{subsection.3.4.1}\protected@file@percent }
\newlabel{subsec:high_level}{{3.4.1}{54}{High-Level Architecture}{subsection.3.4.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces High-Level System Architecture}}{54}{figure.caption.36}\protected@file@percent }
\newlabel{fig:architecture}{{3.3}{54}{High-Level System Architecture}{figure.caption.36}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Multi-threaded Architecture with Inter-Thread Communication}}{55}{figure.caption.37}\protected@file@percent }
\newlabel{fig:thread_comm}{{3.4}{55}{Multi-threaded Architecture with Inter-Thread Communication}{figure.caption.37}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.2}Decision Fusion Logic Flow}{55}{subsection.3.4.2}\protected@file@percent }
\newlabel{subsec:fusion_logic}{{3.4.2}{55}{Decision Fusion Logic Flow}{subsection.3.4.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Decision Fusion Logic Flowchart}}{56}{figure.caption.38}\protected@file@percent }
\newlabel{fig:fusion_flow}{{3.5}{56}{Decision Fusion Logic Flowchart}{figure.caption.38}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Implementation and Results}{58}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:implementation}{{4}{58}{Implementation and Results}{chapter.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Hardware Implementation and OS Configuration}{58}{section.4.1}\protected@file@percent }
\newlabel{sec:hardware_impl}{{4.1}{58}{Hardware Implementation and OS Configuration}{section.4.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}Initial Setup and OS Choice}{58}{subsection.4.1.1}\protected@file@percent }
\newlabel{subsec:os_setup}{{4.1.1}{58}{Initial Setup and OS Choice}{subsection.4.1.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.2}Overcoming Foundational Setup Challenges}{58}{subsection.4.1.2}\protected@file@percent }
\newlabel{subsec:setup_challenges}{{4.1.2}{58}{Overcoming Foundational Setup Challenges}{subsection.4.1.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Software Implementation: Experimental Benchmarking}{59}{section.4.2}\protected@file@percent }
\newlabel{sec:benchmarking}{{4.2}{59}{Software Implementation: Experimental Benchmarking}{section.4.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Testing Procedures}{59}{subsection.4.2.1}\protected@file@percent }
\newlabel{subsec:testing_procedures}{{4.2.1}{59}{Testing Procedures}{subsection.4.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}Results: Face Detector Comparison}{60}{subsection.4.2.2}\protected@file@percent }
\newlabel{subsec:face_detector_results}{{4.2.2}{60}{Results: Face Detector Comparison}{subsection.4.2.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces Face Detector Performance Comparison on Raspberry Pi 4}}{60}{table.caption.39}\protected@file@percent }
\newlabel{tab:face_detector}{{4.1}{60}{Face Detector Performance Comparison on Raspberry Pi 4}{table.caption.39}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Face Detector Benchmark Results on Raspberry Pi 4}}{60}{figure.caption.40}\protected@file@percent }
\newlabel{fig:face_detector_benchmark}{{4.1}{60}{Face Detector Benchmark Results on Raspberry Pi 4}{figure.caption.40}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.3}Results: Face Recognition Model Comparison}{61}{subsection.4.2.3}\protected@file@percent }
\newlabel{subsec:face_recog_results}{{4.2.3}{61}{Results: Face Recognition Model Comparison}{subsection.4.2.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.2}{\ignorespaces Face Recognition Model Performance Comparison}}{61}{table.caption.41}\protected@file@percent }
\newlabel{tab:face_recognition}{{4.2}{61}{Face Recognition Model Performance Comparison}{table.caption.41}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Face Recognition Model Benchmark: Size vs. Speed Trade-off}}{61}{figure.caption.42}\protected@file@percent }
\newlabel{fig:face_recog_benchmark}{{4.2}{61}{Face Recognition Model Benchmark: Size vs. Speed Trade-off}{figure.caption.42}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.4}Results: Voice Verification Toolkit Comparison}{61}{subsection.4.2.4}\protected@file@percent }
\newlabel{subsec:voice_results}{{4.2.4}{61}{Results: Voice Verification Toolkit Comparison}{subsection.4.2.4}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.3}{\ignorespaces Speaker Verification Toolkit Performance Comparison}}{61}{table.caption.43}\protected@file@percent }
\newlabel{tab:voice_verification}{{4.3}{61}{Speaker Verification Toolkit Performance Comparison}{table.caption.43}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Speaker Verification Toolkit Benchmark Results}}{62}{figure.caption.44}\protected@file@percent }
\newlabel{fig:voice_benchmark}{{4.3}{62}{Speaker Verification Toolkit Benchmark Results}{figure.caption.44}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Findings and Analysis}{62}{section.4.3}\protected@file@percent }
\newlabel{sec:findings}{{4.3}{62}{Findings and Analysis}{section.4.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}Analysis of Model Selection}{62}{subsection.4.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2}Initial System Performance Estimation}{62}{subsection.4.3.2}\protected@file@percent }
\newlabel{subsec:performance_estimation}{{4.3.2}{62}{Initial System Performance Estimation}{subsection.4.3.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Estimated System Latency with Parallel Pipeline Execution}}{63}{figure.caption.45}\protected@file@percent }
\newlabel{fig:performance_estimation}{{4.4}{63}{Estimated System Latency with Parallel Pipeline Execution}{figure.caption.45}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.3}Key Technical Insights}{63}{subsection.4.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Conclusion and Future Work}{64}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:conclusion}{{5}{64}{Conclusion and Future Work}{chapter.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Project Summary}{64}{section.5.1}\protected@file@percent }
\newlabel{sec:summary}{{5.1}{64}{Project Summary}{section.5.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Problems Faced and Lessons Learned}{64}{section.5.2}\protected@file@percent }
\newlabel{sec:lessons}{{5.2}{64}{Problems Faced and Lessons Learned}{section.5.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.1}Lesson 1: The Importance of Strategic De-scoping}{64}{subsection.5.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.2}Lesson 2: Embedded Environments are Not Desktops}{65}{subsection.5.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.3}Lesson 3: Empirical Data Trumps Theoretical Performance}{65}{subsection.5.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.4}Lesson 4: User Experience vs. Technical Complexity Trade-off}{65}{subsection.5.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Future Recommendations (FYP-II Work)}{66}{section.5.3}\protected@file@percent }
\newlabel{sec:future}{{5.3}{66}{Future Recommendations (FYP-II Work)}{section.5.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Proposed FYP-II Development Roadmap}}{66}{figure.caption.46}\protected@file@percent }
\newlabel{fig:future_roadmap}{{5.1}{66}{Proposed FYP-II Development Roadmap}{figure.caption.46}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.1}Phase 1: Modular Development}{66}{subsection.5.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.2}Phase 2: Implementation of the Decision Fusion Engine}{66}{subsection.5.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.3}Phase 3: Integration and GPIO Control}{66}{subsection.5.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.4}Phase 4: Rigorous System-Level Testing}{67}{subsection.5.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.5}Phase 5: ONNX Optimization (Stretch Goal)}{67}{subsection.5.3.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Concluding Remarks}{67}{section.5.4}\protected@file@percent }
\newlabel{sec:concluding}{{5.4}{67}{Concluding Remarks}{section.5.4}{}}
\bibcite{facenet}{1}
\bibcite{arcface}{2}
\bibcite{mobilefacenet}{3}
\bibcite{blazeface}{4}
\bibcite{ecapa_tdnn}{5}
\bibcite{ge2e}{6}
\bibcite{resemblyzer}{7}
\bibcite{mtcnn}{8}
\bibcite{insightface}{9}
\bibcite{onnx}{10}
\bibcite{onnx_runtime}{11}
\bibcite{multimodal_camera_ppg}{12}
\bibcite{multimodal_robustness}{13}
\bibcite{multimodal_accessibility}{14}
\bibcite{anti_spoofing_multimodal}{15}
\bibcite{adaptive_multimodal}{16}
\bibcite{deep_hashing_multimodal}{17}
\bibcite{ml_score_fusion}{18}
\bibcite{quality_dependent_fusion}{19}
\bibcite{audio_visual_lip}{20}
\bibcite{gumbel_bimodal}{21}
\bibcite{cross_modal_biometric}{22}
\bibcite{transformer_multimodal}{23}
\bibcite{behavepassdb}{24}
\bibcite{speakingfaces}{25}
\bibcite{smartphone_multimodal}{26}
\bibcite{mobibits}{27}
\bibcite{privacy_edge_biometric}{28}
\bibcite{edge_latency_biometric}{29}
\bibcite{network_independent_biometric}{30}
\bibcite{bandwidth_edge}{31}
\bibcite{edge_scalability}{32}
\bibcite{revamp2t}{33}
\bibcite{facial_expression_edge}{34}
\bibcite{smartphone_sensors_auth}{35}
\bibcite{neuromorphic_vs_edge}{36}
\bibcite{binarynet_covid_mask}{37}
\bibcite{memory_efficient_sv}{38}
\bibcite{pruning_biometric}{39}
\bibcite{distillation_edge}{40}
\bibcite{mobilenet_edge}{41}
\bibcite{efficientnet_biometric}{42}
\bibcite{shufflenet_edge}{43}
\bibcite{squeezenet_biometric}{44}
\bibcite{edgecnn}{45}
\bibcite{early_exit_biometric}{46}
\bibcite{adaptive_resolution}{47}
\bibcite{quality_aware_processing}{48}
\bibcite{edge_emotion_service}{49}
\bibcite{encrypted_similarity}{50}
\bibcite{semba_multimodal}{51}
\bibcite{federated_biometric}{52}
\bibcite{differential_privacy_biometric}{53}
\bibcite{metamorphosis_privacy}{54}
\bibcite{asvspoof_challenge}{55}
\bibcite{sasv_optimization}{56}
\bibcite{ssl_antispoofing}{57}
\bibcite{deepfake_detection_bimodal}{58}
\bibcite{multimodal_pad}{59}
\bibcite{adversarial_voice_attack}{60}
\bibcite{malacopula_attack}{61}
\bibcite{adversarial_training_biometric}{62}
\bibcite{input_transform_defense}{63}
\bibcite{certified_defense}{64}
\bibcite{behavioral_biometric_survey}{65}
\bibcite{mobile_behavioral_biometric}{66}
\bibcite{location_auth}{67}
\bibcite{temporal_auth}{68}
\bibcite{environmental_context}{69}
\bibcite{multidevice_auth}{70}
\bibcite{zero_trust_metaverse}{71}
\bibcite{children_sv}{72}
\bibcite{age_agnostic_sv}{73}
\bibcite{cross_age_disentangle}{74}
\bibcite{self_distillation_sv}{75}
\bibcite{self_supervised_sv_wavlm}{76}
\bibcite{speaker_interpolation}{77}
\bibcite{text_dependent_sv}{78}
\bibcite{text_adaptation_sv}{79}
\bibcite{chinese_numerical_sv}{80}
\bibcite{far_field_sv}{81}
\bibcite{low_light_enhancement}{82}
\bibcite{noise_robust_sv}{83}
\bibcite{explainable_phonetic_sv}{84}
\bibcite{3d_speaker_toolkit}{85}
\bibcite{ssl_foundation_biometric}{86}
\bibcite{attribution_biometric}{87}
\bibcite{speaker_embedding_interpretation}{88}
\bibcite{calibration_biometric}{89}
\bibcite{tinysv}{90}
\bibcite{binary_nn_biometric}{91}
\bibcite{event_camera_expression}{92}
\bibcite{synthetic_emotion_faces}{93}
\bibcite{tts_augmentation}{94}
\bibcite{synthetic_domain_adapt}{95}
\bibcite{snn_biometric}{96}
\bibcite{in_memory_biometric}{97}
\bibcite{analog_nn_biometric}{98}
\bibcite{depth_width_tradeoff}{99}
\bibcite{conv_vs_transformer_edge}{100}
\bibcite{task_specific_models}{101}
\@writefile{toc}{\contentsline {chapter}{\numberline {A}Installation Guide}{75}{appendix.A}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{app:installation}{{A}{75}{Installation Guide}{appendix.A}{}}
\@writefile{toc}{\contentsline {section}{\numberline {A.1}Raspberry Pi OS Setup}{75}{section.A.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {A.2}Python Environment Setup}{76}{section.A.2}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {B}Code Snippets}{77}{appendix.B}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{app:code}{{B}{77}{Code Snippets}{appendix.B}{}}
\@writefile{toc}{\contentsline {section}{\numberline {B.1}Face Detection with BlazeFace}{77}{section.B.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {B.2}Voice Embedding with Resemblyzer}{78}{section.B.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {B.3}Decision Fusion Engine (Pseudocode)}{78}{section.B.3}\protected@file@percent }
\gdef \@abspage@last{93}
